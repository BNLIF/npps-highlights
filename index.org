#+title: EDG Highlights for NPPS
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="org.css"/>

This page attempts to collect highlights of software-related activity
by EDG members that may be interesting to NPPS.  Below are weekly
summaries.  Less frequently updated but more focused updates on
Wire-Cell can be found in the [[https://wirecell.github.io/news/][Wire-Cell News blog]].

* [2020-02-07 Fri]

- ZIO is reached a milestone of functionality for its first use
  (multi-threaded file I/O) and now has a set of [[https://brettviren.github.io/zio/tutorial.html][tutorials]], one for
  each major concept.  Focus is not on the next phase which is
  providing support for CPU/GPU resource balancing brokers.  This
  started with providing back to the ZeorMQ community an [[https://github.com/booksbyus/zguide/commit/d1818973c6a21605c18e452a4d64c8fc8342f6a2][upgrade]] to
  the Majordomo example from the [[http://zguide.zeromq.org/page:all#toc98][Zguide]].

- Haiwang continues his work on [[https://indico.bnl.gov/event/7608/contributions/34912/attachments/26525/40172/2019-02-06_Integration.pdf][DL ROI finding]] as part of Wire-Cell
  Toolkit LArTPC signal processing.  His technique gets superior
  efficiency and purity for collecting ionization signals especially
  for difficult high-angle tracks.  Running inference on CPU takes
  about 24 s per event and on GPU about 200 ms which is now comparable
  to times required for internal data conversion.  Profiling the job
  and making some optimistic linear scaling assumptions indicate one
  GPU (2080ti) would require 2500 CPU cores running the rest of the
  WCT payload in order to balance the two resources.

- Kwang Min Yu (CSI), Haiwang and BV met to discuss Kwang Min's recent
  developments in porting parts of Wire-Cell Toolkit's drift
  simulation to GPU.  He achieves 4.7x speed increase in the code
  itself providing 2.6x speed up in the overall simulation job.  The
  code involves rastering each 2D Gaussian model of drifted ionization
  energy depositions onto a small "patch" grid and applying binomial
  fluctuations.  The next step for these patches are to sum them onto
  a larger grid and perform convolution with detector response.  This
  summing inherently resists GPU parallelism.  Kwang Min described
  possible "divide and conquer" strategies to attack this problem and
  this would be the next step but first Haiwang and BV need to "catch"
  up by understanding the GPU code and integrating it into WCT,
  proper.

- Wenqian Gu has been trying to understand potential disagreement in
  dE/dX in Wire-Cell Toolkit.  This may be usual confusion over
  Geant4's energy "deposition" vs energy "loss" or it may be some real
  problem.  The discrepancy was larger when larger max step size in
  Geant4 was used.  Going from 0.9mm to 0.3mm allows the discrepancy
  to be removed by an ad-hoc 15% "calibration".  Work is ongoing to
  understand the nature of this.

- Next week is a DUNE DAQ workshop at CERN.


* [2020-01-31 Fri]

Xmas/New Years and general laziness mean these updates cover more than
one week of activity.

- Wire-Cell Toolkit release branch 0.13.x made (Haiwang) with release
  [[https://github.com/WireCell/wire-cell-toolkit/releases/tag/0.13.0][0.13.0]] and quickly following [[https://github.com/WireCell/wire-cell-toolkit/releases/tag/0.13.1][0.13.1]] which just removed some cruft
  unintentionally left in.  They are the first release after moving
  the toolkit source to a mono-repo assembled from the old individual
  repos using [[https://github.com/ingydotnet/git-subrepo][git subrepo]] and includes many important algorithm
  additions and improvements not the least of which is bringing back
  support for multi-threaded graph execution and support for deep
  network machine learning based signal-ROI finding.  More details
  listed in the 0.13.0 release notes.

  - Tangentially unrelated, the LArSoft source code management has
    moved from Fermilab Redmine to https://github.com/larsoft.  It
    now follows a fork+PR-based contribution model.

- [[https://github.com/brettviren/zio][ZIO]] has matured greatly since last update but still has more to
  come.  Since last highlight, it has gained an implementation of the
  [[http://zguide.zeromq.org/page:all#toc211]["credit based flow control"]] protocol described in the ZeroMQ guide.
  However, ZIO flow uses SERVER/CLIENT sockets (in draft) instead of
  ROUTER/DEALER in order to assure thread safety if/when sockets are
  utilized from changing threads (as will happen with TBB based
  multi-thread graph exeuction).  ZIO now includes both C++ and Python
  implementation of the major patterns (~message~, ~peer~, ~node~, ~port~ and
  ~flow~).  A documentation website for [[https://brettviren.github.io/zio/][ZIO]] was started.

- The WCT subpackage [[https://github.com/brettviren/wire-cell-zpb][ZPB]] was started.  It provides the WCT end of a
  ZIO flow.  It also has a documentation home page: [[https://brettviren.github.io/wire-cell-zpb/][ZPB]].  Current ZPB
  functionality includes extracting WCT "depo" and "frame" data types
  from components running inside the single or multi-threaded WCT
  graph execution engines, conversion to protobuf (the "PB" in "ZPB")
  objects in ZIO messages, transferring them over ZIO/ZeroMQ (the "Z"
  in "ZPB"), receiving the message in a broker and saving to HDF5.
  Reading/injecting back into the graph is nearly complete.  The
  broker is implemented generically in Python in the ZIO Python
  package and ZPB provides a domain-specific "broker factory plugin"
  which itself is plugable for both the message payload schema (but
  limited to just protobuf format for now) and the file format (HDF5
  implemented, ROOT maybe next).

* [2019-12-13 Fri]

- DUNE DAQ is discussing software build and other software management
  issues.  FNAL is trying to replace their long standing "augmented"
  CMake package-level build system + their suite of shell scripted
  meta build system with a new "augmented" CMake build system + Spack.
  (editorial comment: the latter is welcome, but the former is still a
  core mistake that limits the portability of code that employs the
  "augmented" CMake package build.)

- The ZIO package started last week has reached a maturity to go on to
  the next step of seeing how to integrate it into Wire-Cell toolkit.
  A likely problem was uncovered in mixing Zio's ZeroMQ with WCT's MT
  graph execution engine based on TBB "flow graph": in general, ZMQ
  sockets can not be sent across thread boundaries without hitting
  undefined behavior.  Work is still ongoing to understand and
  demonstrate the problem but it may be a show stopper in mixing these
  two technologies.  Any input on this topic from the group is very
  welcome.

* [2019-12-06 Fri]

- BV and Haiwang met with CSI (Meifeng, Kwangmin, Zhihua) yesterday to
  sync up about recent HEP-CCE activities as well as Wire-Cell
  parallelizing/optimizing.  BV was asked to participate in CCE-IOS
  (I/O + storage, meeting next Friday), Meifeng is in CCE-PPS
  (portable parallelism, meeting next Monday) and asked BV to
  participate in that as well.  

  Haiwang reported on his recent work on Wire-Cell's component-level
  parallel execution engine based on TBB.  Single threaded jobs are
  just above 1 GB, multi-threaded jobs with 1 pipeline for each of 6
  ProtoDUNE APAs achieves near 600% CPU usage in those pipelines and
  uses less than 3 GB.  

  Haiwang also presented his work on improvements on the quality of
  the "region-of-interest" half of Wire-Cell signal processing via
  machine learning techniques based on image segmentation.  Evaluation
  is based on visually checking ROI results and is clearly better than
  the current heuristic based ROI finding in terms of completeness and
  spatial resolution.  Kwangmin remarked on the relatively low number
  of training epochs used (5) and Haiwang will investigate how results
  might change as a function of this number.

- A new project ([[https://github.com/brettviren/zio][zio]]) was started as a basis for solutions of several
  similar problems but in rather different spaces.  Some additional
  info is in the README and updates will be provided as the project
  develops.

- The [[https://github.com/brettviren/tpquery][TP Query]] package for DUNE FD DAQ reached an initial milestone of
  usability.  It provides a ZeroMQ based streamed buffer query system
  based on interval trees and applied to providing a database of
  recent self-trigger information for ProtoDUNE.  It was tested using
  PTMP's "replay" mechanism with trigger messages dumped from
  ProtoDUNE.  It sustains sufficient throughput for buffers of a few
  seconds deep for the aggregate of 1 APA (~80kHz of intervals) but
  will slow beyond that (the relevant interval tree operations are
  N*log(N)).  This is likely sufficient as-is but at least one
  approach exists to combat this slowdown if longer buffers are
  needed.  It's unclear when this might be tested "live" at ProtoDUNE
  but it was recently learned that PDSP will run into April.
  Unidentified artdaq developer effort is needed if this buffer query
  is to lead to data sent to offline files but a quicker "live" test
  can be developed entirely using PTMP based code.

* [2019-11-22 Fri]

- DUNE computing issued a charge for a "DUNE Software Framework
  Requirements Task Force":

  https://indico.fnal.gov/event/22493/contribution/9/material/slides/3.pdf

  to be led by Paul Laycock and Andrew Norman (of FNAL).

- Report on Wire-Cell Toolkit to LArSoft Coordination meeting by
  Haiwang Yu

  https://indico.fnal.gov/event/22501/contribution/1/material/slides/0.pdf

  Good overview of WCT's data flow programming paradigm, some of the
  algorithms, initial look at ROOT vs HDF5, single/multi-threading
  comparisong, memory usage, identified lock bottleneck in FFTW3.

- DUNE FD DAQ began technical discussions about how to handle
  "observability" with initial focus on metrics.  Two presentations
  are here https://indico.fnal.gov/event/22481/.  Of particular note
  to NPPS, I mentioned Sergey Padolski's BDT work for Panda as
  something we should look into more.

* [2019-11-15 Fri]

- [[https://indico.bnl.gov/event/6383/contributions/32818/attachments/25515/38251/srv-dune-fd-daq-bv.pdf][DUNE DAQ at SRV]] describes the prototype streaming trigger/readout software and some results of [[https://github.com/brettviren/zperfmq][ZeroMQ performance]] on 100 Gbps ATLAS/DUNE/sPHENIX LDRD test network.

- [[https://www.bnl.gov/dmo2019/][Module of oprotunity]] workshop at BNL discussed what DUNE might put in as the fourth of four far detector modules.  Mostly physics and detector related.   [[https://indico.fnal.gov/event/21535/contribution/22/material/slides/0.pptx][Xin Qian's talk]] shows many Wire-Cell results and includes some new ideas on LArTPC signal processing including early promising results using deep learning by our post-doc Haiwang Yu.

- Couple of notes posted
  - [[http://docs.dunescience.org/cgi-bin/ShowDocument?docid=16973][DUNE DocDB 16973]] some unfinished notes on "observability" systems of possible interest for DUNE FD DAQ.
  - [[http://docs.dunescience.org/cgi-bin/ShowDocument?docid=16976][DUNE DocDB 16976]] write up of performance evaluation of ZeroMQ on 100 Gbps using ZperfMQ.

